\documentclass[assignment03_Solutions]{subfiles}

\IfSubStr{\jobname}{\detokenize{Solutions}}{\toggletrue{solutions}}{\toggletrue{solutions}}

\fancypagestyle{firstpage}

{\rhead{Assignment 3 \linebreak \textit{Version: \today}}}

\title{Assignment 3: Fairness, Maximum Likelihood Estimation, and Text Classification}
\author{Machine Learning}
\date{Fall 2019}
\invalidatemargin

\begin{document}

\maketitle
\thispagestyle{firstpage}


\begin{learningobjectives}
\bi
\item TODO
\ei
\end{learningobjectives}

\section{Bayesian Networks and Algorithmic Fairness}


In assignment 1 of this module we discussed how Bayesian methods can be used to reason about algorithmic fairness.  We've just had some lengthy discussions about fairness within the context of the Compas algorithm.  We touched upon some of the limitations of statistically based notions of fairness.  Nevertheless, they do have a potential role to play, and you should know what the most common definitions of fairness are and what assumptions they make.

As context for the reading and to help us have common notation, suppose we have the following random variables.

\bi
\item $R$ is a prediction generated by our algorithm.
\item $A$ is a sensitive attribute
\item $Y$ is the thing we're trying to predict (we want $R = Y$ if we are predicting accurately)
\ei

\begin{externalresources}[(30 minutes)]
Read \href{https://fairmlbook.org/classification.html}{Fairness and Machine Learning Chapter 2}.  Start at the section \emph{Formal non-discrimination criteria} and read up to (but not including) the section \emph{Calibration and sufficiency}.
\begin{notice}
\bi
\item Don't get hung up on the \href{https://en.wikipedia.org/wiki/Receiver_operating_characteristic}{ROC curves}.  We can certainly discuss this on NB, but it is not required to understand what is going on here.  The presentation earlier in the linked reading is also pretty clear.
\item The notation they use in this reading for conditional independence is an upside down T with only one line (instead of our notation, $\condindep$).
\ei
\end{notice}
\end{externalresources}


\begin{exercise}[(5 minutes)]
Thinking back to the COMPAS example, which definition of fairness given in the reading was Propublica using?  Which definition of fairness was Northpointe using?

\begin{boxedsolution}
\bi
\item Northpointe is using sufficiency $Y \condindep A~|~R$.  You'll notice that in the reading they say that sufficiency is the same thing as matching positive and negative predictive value for all values of the protected attribute.
\item Propublica is using separation $R \condindep A~|~Y$.  This fairness principle requires the false positive and true positive rates to be the same across for all values of the protected attribute.
\ei
\end{boxedsolution}
\end{exercise}

TODO: possibly present the data from COMPAS in \href{https://colab.research.google.com/drive/1HMX0GJAF0PcCn6INfCoeqNOASJri_V_s}{a notebook}.


\section{Text Classification with Bag of Words}
Next we'll be applying Na\"ive Bayes to the task of classifying text.

\begin{externalresources}[(45 minutes)]
This will be done in the \href{https://colab.research.google.com/github/mlfa19/assignments/blob/master/Module\%202/03/Assignment_3_Companion_Notebook.ipynb}{Assignment 3 companion notebook}.
\end{externalresources}

\section{The Intelligent Design of Jenny Chow}

This assignment is fully described on the \href{https://canvas.instructure.com/courses/1659968/assignments/12785465?module_item_id=26196347}{Intelligent Design of Jenny Chow Canvas page}.  There is also an alternative described on the assignment page if you can't attend.  Make sure to look at the assignment before going to the play since we are asking you to capture some of your reactions / thoughts so that you can bring them to class on Monday for discussion.

\end{document}
