{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Analyze Fake Coin Flips.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlfa19/assignments/blob/master/Module%202/day04/Analyze%20Fake%20Coin%20Flips.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLvGMNqjpIqd",
        "colab_type": "text"
      },
      "source": [
        "# Sequence Classification: Analyzing Coin Flips\n",
        "\n",
        "In this notebook we'll be introducing a simple model of sequence classification based on the concept of n-grams.  You'll be following up more formally on these ideas in the assignment due next class.\n",
        "\n",
        "> Data and some of the main ideas originally from [Can you Fake Coin Tosses?](https://faculty.math.illinois.edu/~hildebr/fakerandomness/)\n",
        "\n",
        "## Modeling Sequences of Coin Flips\n",
        "\n",
        "It turns out that humans are rather bad random number generators. If you ask a person to simulate a random sequence (e.g., flipping a coin a number of time), they will almost always introduce patterns in the sequence that you would not see if it were genuinely random.  A cool example of this in action is the [mind reader app](http://mindreaderpro.appspot.com/) put together by Yoav Freund's group at UC San Diego.\n",
        "\n",
        "In this notebook we'll be using conditional probabilities as a way to understand the difference between real and fake coin toss sequences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vk_duMIpIqg",
        "colab_type": "text"
      },
      "source": [
        "First, we'll load the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JTNmrH8pIqh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fccfd38d-298f-47e1-d6d1-cf46ab5abb4c"
      },
      "source": [
        "import pandas as pd\n",
        "import gdown\n",
        "\n",
        "gdown.download('https://drive.google.com/uc?authuser=0&id=1lAVLg9cxYxXL9kwIZI7T0xG128DVLlvw&export=download',\n",
        "               'coin_flips.csv',\n",
        "               quiet=False)\n",
        "df_fake = pd.read_csv('coin_flips.csv')\n",
        "df_fake"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?authuser=0&id=1lAVLg9cxYxXL9kwIZI7T0xG128DVLlvw&export=download\n",
            "To: /content/coin_flips.csv\n",
            "100%|██████████| 9.83k/9.83k [00:00<00:00, 5.75MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student</th>\n",
              "      <th>flips</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>math199chp2017fall1</td>\n",
              "      <td>0000011001000011101010011101111010001110110100...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>math199chp2017fall2</td>\n",
              "      <td>0010101100010111100101011000101100100011011001...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>math199chp2017fall3</td>\n",
              "      <td>0000101010001010011111001011110010110000000101...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>math199chp2017fall4</td>\n",
              "      <td>1101001110101001110101100001101101000100111010...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>math199chp2017fall5</td>\n",
              "      <td>0010100111011011010110000110010011000101100110...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>math199chp2017fall6</td>\n",
              "      <td>0010110001011110101011001101010001101011110010...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>math199chp2017fall7</td>\n",
              "      <td>0001011010010111100101001001110110100100001101...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>math199chp2017fall8</td>\n",
              "      <td>1011010011100101101000011101001110100110100110...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>math199chp2017fall9</td>\n",
              "      <td>0011101100101001001011011000011010110111011101...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>math199chp2017fall10</td>\n",
              "      <td>0010100011110101100100111001011001101000110101...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>math199chp2017fall11</td>\n",
              "      <td>0110100011011010011101100001010100110100111001...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>math199chp2017fall12</td>\n",
              "      <td>1000101101011001000111100011111010011000010110...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>math199chp2017fall13</td>\n",
              "      <td>0001001100111101001110110001010100100011111011...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>math199chp2017fall14</td>\n",
              "      <td>0010001101111101010111001010110110001101011011...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>math199chp2017fall15</td>\n",
              "      <td>0010110001011000101001011001011110100100100110...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>math199chp2017fall16</td>\n",
              "      <td>0110100011010011110111000111110010001101100001...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>math199chp2017fall17</td>\n",
              "      <td>1011111011011010010000111001011000011011010001...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>math199chp2017fall18</td>\n",
              "      <td>1000101101111001100100010010111010011010000011...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>math199chp2015spring1</td>\n",
              "      <td>0001010101110110010000000001110101011110101000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>math199chp2015spring2</td>\n",
              "      <td>0110101001010101010011010010101010101010101101...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>math199chp2015spring3</td>\n",
              "      <td>0101010000011101010000100101010100111101000110...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>math199chp2015spring4</td>\n",
              "      <td>0000000000010000001111111101010000000000111101...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>math199chp2015spring5</td>\n",
              "      <td>0010010000111111011010101000100010000101101000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>math199chp2015spring6</td>\n",
              "      <td>0010011100010010101001010001000100111000110010...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>math199chp2015spring7</td>\n",
              "      <td>0010011101011001011001010100101111111001001101...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>math199chp2015spring8</td>\n",
              "      <td>1001100100110111110010101011010110101101101101...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>math199chp2015spring9</td>\n",
              "      <td>1001010100101010001010010111010010001001010101...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>math199chp2015spring10</td>\n",
              "      <td>0000111101011010001010101111010000101010001011...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>math199chp2015spring11</td>\n",
              "      <td>0110100101010010001010101001010000101010100100...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>math199chp2016spring10</td>\n",
              "      <td>1110110101100101010101011010101010101010100010...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>math199chp2016spring11</td>\n",
              "      <td>1011010010110100100011101010010101001110101111...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>math199chp2016spring12</td>\n",
              "      <td>0000000000111000000111010101111101000010001010...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>math199chp2016spring13</td>\n",
              "      <td>0100111001001101001000110010010011001010010010...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>math199chp2016spring14</td>\n",
              "      <td>0101010111110010101001010110010101101010101000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>math199chp2016spring15</td>\n",
              "      <td>0010110010100111010101111100010011110011000100...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>math199chp2016spring16</td>\n",
              "      <td>1010101111100101010101100000110101011011111101...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>math199chp2016spring17</td>\n",
              "      <td>0101110101010110101011101010101010101010110101...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>math199chp2016spring18</td>\n",
              "      <td>1011001010010101011000101011001010100101010111...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>math199chp2016spring19</td>\n",
              "      <td>0101010101110110101010101011100001010101010101...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>math199chp2016spring20</td>\n",
              "      <td>0001101110111010101000101001110101010101010101...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>math199chp2016spring21</td>\n",
              "      <td>0001010011110010101101110100110101100100101100...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   student                                              flips\n",
              "0      math199chp2017fall1  0000011001000011101010011101111010001110110100...\n",
              "1      math199chp2017fall2  0010101100010111100101011000101100100011011001...\n",
              "2      math199chp2017fall3  0000101010001010011111001011110010110000000101...\n",
              "3      math199chp2017fall4  1101001110101001110101100001101101000100111010...\n",
              "4      math199chp2017fall5  0010100111011011010110000110010011000101100110...\n",
              "5      math199chp2017fall6  0010110001011110101011001101010001101011110010...\n",
              "6      math199chp2017fall7  0001011010010111100101001001110110100100001101...\n",
              "7      math199chp2017fall8  1011010011100101101000011101001110100110100110...\n",
              "8      math199chp2017fall9  0011101100101001001011011000011010110111011101...\n",
              "9     math199chp2017fall10  0010100011110101100100111001011001101000110101...\n",
              "10    math199chp2017fall11  0110100011011010011101100001010100110100111001...\n",
              "11    math199chp2017fall12  1000101101011001000111100011111010011000010110...\n",
              "12    math199chp2017fall13  0001001100111101001110110001010100100011111011...\n",
              "13    math199chp2017fall14  0010001101111101010111001010110110001101011011...\n",
              "14    math199chp2017fall15  0010110001011000101001011001011110100100100110...\n",
              "15    math199chp2017fall16  0110100011010011110111000111110010001101100001...\n",
              "16    math199chp2017fall17  1011111011011010010000111001011000011011010001...\n",
              "17    math199chp2017fall18  1000101101111001100100010010111010011010000011...\n",
              "18   math199chp2015spring1  0001010101110110010000000001110101011110101000...\n",
              "19   math199chp2015spring2  0110101001010101010011010010101010101010101101...\n",
              "20   math199chp2015spring3  0101010000011101010000100101010100111101000110...\n",
              "21   math199chp2015spring4  0000000000010000001111111101010000000000111101...\n",
              "22   math199chp2015spring5  0010010000111111011010101000100010000101101000...\n",
              "23   math199chp2015spring6  0010011100010010101001010001000100111000110010...\n",
              "24   math199chp2015spring7  0010011101011001011001010100101111111001001101...\n",
              "25   math199chp2015spring8  1001100100110111110010101011010110101101101101...\n",
              "26   math199chp2015spring9  1001010100101010001010010111010010001001010101...\n",
              "27  math199chp2015spring10  0000111101011010001010101111010000101010001011...\n",
              "28  math199chp2015spring11  0110100101010010001010101001010000101010100100...\n",
              "29  math199chp2016spring10  1110110101100101010101011010101010101010100010...\n",
              "30  math199chp2016spring11  1011010010110100100011101010010101001110101111...\n",
              "31  math199chp2016spring12  0000000000111000000111010101111101000010001010...\n",
              "32  math199chp2016spring13  0100111001001101001000110010010011001010010010...\n",
              "33  math199chp2016spring14  0101010111110010101001010110010101101010101000...\n",
              "34  math199chp2016spring15  0010110010100111010101111100010011110011000100...\n",
              "35  math199chp2016spring16  1010101111100101010101100000110101011011111101...\n",
              "36  math199chp2016spring17  0101110101010110101011101010101010101010110101...\n",
              "37  math199chp2016spring18  1011001010010101011000101011001010100101010111...\n",
              "38  math199chp2016spring19  0101010101110110101010101011100001010101010101...\n",
              "39  math199chp2016spring20  0001101110111010101000101001110101010101010101...\n",
              "40  math199chp2016spring21  0001010011110010101101110100110101100100101100..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttlUklrjpIql",
        "colab_type": "text"
      },
      "source": [
        "To get a better sense of one of these sequences, let's zoom in on the first entry."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I8psbQOpIql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b84e47f7-e66b-427e-fcf9-818e90c90a10"
      },
      "source": [
        "print(df_fake.iloc[0]['flips'])\n",
        "print('total flips', len(df_fake.iloc[0]['flips']))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0000011001000011101010011101111010001110110100111101000110010111100011111110011101100001011100010110001101000001010110100010100101000101101111101100101111010111010010111110010111001010101001011110010010000101\n",
            "total flips 208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eajTv-zpIqn",
        "colab_type": "text"
      },
      "source": [
        "This shows a sequence of heads and tails (1 is heads and 0 is tails).  In this case there were a total of 208 flips."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-V6FchUpIqo",
        "colab_type": "text"
      },
      "source": [
        "## Classifying Sequences as Human or Computer Generated\n",
        "\n",
        "While the pattern of heads (1's) and tails (0's) above might look random, it is reasonable to ask the question of whether there is some feature of the sequence that is different from an actual random sequence of coin flips.\n",
        "\n",
        "As a way to test this we're going to generate a bunch of random sequences of coin flips using Python's `random` module (of course computers are only pseudo-random, but for our purposes here we can think of them as genuinely random)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whji1KxUpIqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import randint\n",
        "def sample_random_flips(x):\n",
        "    return ''.join(str(randint(0,1)) for _ in range(len(x)))\n",
        "\n",
        "# df_real will be a data frame of random flips generated using python's random number\n",
        "# generator.  Each sequence will have the same number of flips as one of the coin toss\n",
        "# sequences generated by humans.\n",
        "df_real = df_fake.copy()\n",
        "df_real['flips'] = df_fake['flips'].map(sample_random_flips)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2Dbodm0pIqq",
        "colab_type": "text"
      },
      "source": [
        "In the next block of code we're going to be creating some new columns in our data frames that represent the probability of seeing various binary sequences occur within either the real or fake data.  Once we've generated these columns, we'll include some more information on what the columns represent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M57C3Gq0pIqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "e4ac2873-4cd7-49ec-e530-7b0974ee11f9"
      },
      "source": [
        "!pip install regex\n",
        "import regex as re\n",
        "import itertools\n",
        "\n",
        "def count_overlapping(text, search_for):\n",
        "    return len(re.findall(search_for, text, overlapped=True))\n",
        "\n",
        "def make_seq_column(df, seq):\n",
        "    df['seq_' + seq] = df['flips'].map(lambda x: count_overlapping(x, seq)/(len(x) - len(seq) + 1))\n",
        "    \n",
        "def populate_length_n_seqs(n):\n",
        "    for s in itertools.product(*([['0', '1']]*n)):\n",
        "        make_seq_column(df_real, ''.join(s))\n",
        "        make_seq_column(df_fake, ''.join(s))\n",
        "\n",
        "for n in range(10):\n",
        "    populate_length_n_seqs(n)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/60/d9782c56ceefa76033a00e1f84cd8c586c75e6e7fea2cd45ee8b46a386c5/regex-2019.08.19-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\r\u001b[K     |▌                               | 10kB 16.8MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |██▌                             | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |████                            | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: regex\n",
            "Successfully installed regex-2019.8.19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvic5hrWpIqt",
        "colab_type": "text"
      },
      "source": [
        "Let's look at the columns `seq_0` to see the probability of observing the length one sequence '0' in each of the sequences.  This represents the overall base rate of tails (0's) in each sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxg-eHZBpIqt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "e5622d5f-69ff-406c-b76c-81499e0a8904"
      },
      "source": [
        "df_fake['seq_0']"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0.480769\n",
              "1     0.533113\n",
              "2     0.529412\n",
              "3     0.500000\n",
              "4     0.477987\n",
              "5     0.493450\n",
              "6     0.507692\n",
              "7     0.489796\n",
              "8     0.466019\n",
              "9     0.505338\n",
              "10    0.502646\n",
              "11    0.465000\n",
              "12    0.483568\n",
              "13    0.477444\n",
              "14    0.491892\n",
              "15    0.487633\n",
              "16    0.500000\n",
              "17    0.503937\n",
              "18    0.505000\n",
              "19    0.450000\n",
              "20    0.555000\n",
              "21    0.585000\n",
              "22    0.610000\n",
              "23    0.550000\n",
              "24    0.475000\n",
              "25    0.440000\n",
              "26    0.595000\n",
              "27    0.500000\n",
              "28    0.560000\n",
              "29    0.520000\n",
              "30    0.545000\n",
              "31    0.510000\n",
              "32    0.540000\n",
              "33    0.510000\n",
              "34    0.470000\n",
              "35    0.510000\n",
              "36    0.450000\n",
              "37    0.530000\n",
              "38    0.540000\n",
              "39    0.485000\n",
              "40    0.501538\n",
              "Name: seq_0, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uuuaDptpIqv",
        "colab_type": "text"
      },
      "source": [
        "There are columns for each of the possible length 10 sequences.  For instance, we can check out `seq_01` to see the probability of observing the sequence \"01\" in each sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRumrWjMpIqw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "510fc4d5-1fd8-4884-df6d-98b174106b61"
      },
      "source": [
        "df_fake['seq_01']"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0.270531\n",
              "1     0.279070\n",
              "2     0.236686\n",
              "3     0.306878\n",
              "4     0.322785\n",
              "5     0.337719\n",
              "6     0.312741\n",
              "7     0.302564\n",
              "8     0.302439\n",
              "9     0.307143\n",
              "10    0.340426\n",
              "11    0.296482\n",
              "12    0.297170\n",
              "13    0.290566\n",
              "14    0.326087\n",
              "15    0.262411\n",
              "16    0.297561\n",
              "17    0.292490\n",
              "18    0.311558\n",
              "19    0.376884\n",
              "20    0.271357\n",
              "21    0.211055\n",
              "22    0.236181\n",
              "23    0.336683\n",
              "24    0.351759\n",
              "25    0.346734\n",
              "26    0.321608\n",
              "27    0.326633\n",
              "28    0.371859\n",
              "29    0.346734\n",
              "30    0.351759\n",
              "31    0.190955\n",
              "32    0.361809\n",
              "33    0.381910\n",
              "34    0.281407\n",
              "35    0.336683\n",
              "36    0.356784\n",
              "37    0.361809\n",
              "38    0.407035\n",
              "39    0.306533\n",
              "40    0.287037\n",
              "Name: seq_01, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSEy-cRKpIqy",
        "colab_type": "text"
      },
      "source": [
        "## Conditional Probabilities and the N-Gram Model\n",
        "\n",
        "At first glance it looks like there are some differences across these sequences with regards to various sequences.  Is this enough to figure out whether a sequence is real or fake?\n",
        "\n",
        "In order to figure this out we're going to use the concept of conditional probabilities.  Specifically, we'll be thinking about the probability of the next symbol in a sequence (in this case heads or tails) given the previous symbols in the sequence.\n",
        "\n",
        "For instance, we might want to know what is the probability that the $n$th element of a sequence is 0 given that the previous element was a 1.  We can represent this as a conditional probability like so.\n",
        "\n",
        "$$p(X_n=1|X_{n-1}=0)$$\n",
        "\n",
        "This probability is also called a bigram since it looks at the probability related to a length 2 sequence (that is the sequence $X_{n-1}, X_{n}$.\n",
        "\n",
        "If we allow for longer conditioning sequences, we get the $n$-gram model ($n$ is the total length of the sequence we're considering).  We'll leave the formal treatment of this for the assignment.\n",
        "\n",
        "Next, we use the sequence columns we computed to define a function to compute conditional probabilities.  Instead of computing conditional probabilities for each sequence independently, we're going to look at the conditional probabilities over ***all the fake sequences***.\n",
        "\n",
        "There is no need to get lost in the details of what is going on in this function.  All that is happening is applying the definition of conditional probability $p(A|B) = \\frac{p(A,B)}{p(B)}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vREl6h36pIqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from functools import lru_cache\n",
        "\n",
        "# Note: we are implicitly passing in df as a way to get around the fact that it is not hashable\n",
        "@lru_cache(maxsize=10**5)\n",
        "def get_conditional_probs(conditioning_seq):\n",
        "    followed_by_1 = df['seq_' + conditioning_seq + '1'] * (df['flips'].map(len)-len(conditioning_seq)-1)\n",
        "    followed_by_0 = df['seq_' + conditioning_seq + '0'] * (df['flips'].map(len)-len(conditioning_seq)-1)\n",
        "    p_1_given_conditioning_seq = followed_by_1.sum()\n",
        "    p_0_given_conditioning_seq = followed_by_0.sum()\n",
        "    return p_0_given_conditioning_seq / (p_1_given_conditioning_seq + p_0_given_conditioning_seq), \\\n",
        "            p_1_given_conditioning_seq / (p_1_given_conditioning_seq + p_0_given_conditioning_seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0hfb53JpIq0",
        "colab_type": "text"
      },
      "source": [
        "In the next cell we're going to analyze the fake data and see what the conditional probability of the next symbol is given the conditioning symbol 010.\n",
        "\n",
        "***Understanding Check***\n",
        "What should the conditional probabilities be if the sequence is actually random?  What does the conditional probability you see below say about how humans generated random sequencdes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyKT4nBipIq0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "688c0675-ae9f-4017-9fcd-45b2ac66bb5b"
      },
      "source": [
        "# Please excuse passing in df_fake through a global variable.  This was a quick and dirty\n",
        "# way of doing memoization with our get_conditional_probs function.\n",
        "df = df_fake\n",
        "get_conditional_probs('010')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3364183139472274, 0.6635816860527727)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQY_0Xm1pIq2",
        "colab_type": "text"
      },
      "source": [
        "In order to see if our model can classify real versus fake sequences we're going to calculate the probability of a test sequence under two models.  The first model is the model derived from the fake sequences.  The second model always assigns a probability of 0.5 to each possible symbol (since for random sequences, each symbol should be independent of the previous symbol).\n",
        "\n",
        "For the performance metric we're using the area under the ROC curve.  As we mentioned last class, the area under the ROC curve tells us the probability that we can correctly determine which of two points is of class 1 and which is of class 0 (assuming we are guaranteed there is exactly one of each)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14K4BdnGpIq3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "727133e7-2790-4ddc-c76c-eed8e6c97ebf"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import time\n",
        "\n",
        "def get_llrs(flips, context_length=2):\n",
        "    \"\"\" Calculate the log likelihoood ratio of the data under the fake model versus the\n",
        "        real model.  We use a log likelihood ratio for the same reason we used it in the\n",
        "        Naive Bayes model.\n",
        "        \n",
        "        If you change context_length, you can see how the performance of the model varies\n",
        "        as you use longer or shorter length sequences for your conditional probabilities.\n",
        "        What seems to work the best? \"\"\"\n",
        "    llrs = []\n",
        "    for s in flips:\n",
        "        context = []\n",
        "        llr = 0\n",
        "        for flip in s:\n",
        "            context_to_use = ''.join(context[-context_length:])\n",
        "            p_0, p_1 = get_conditional_probs(context_to_use)\n",
        "            if flip == '0':\n",
        "                llr += np.log(p_0) - np.log(0.5)\n",
        "            else:\n",
        "                llr += np.log(p_1) - np.log(0.5)\n",
        "            context.append(flip)\n",
        "        llrs.append(llr)\n",
        "    return llrs\n",
        "\n",
        "all_roc_scores = []\n",
        "context_length = 3\n",
        "for iter in range(20):\n",
        "    df_fake_train, df_fake_test = train_test_split(df_fake)\n",
        "    get_conditional_probs.cache_clear()\n",
        "    df = df_fake_train\n",
        "    llrs_positive = np.array(get_llrs(df_fake_test['flips'], context_length))\n",
        "    llrs_negative = np.array(get_llrs(df_real['flips'], context_length))\n",
        "    all_llrs = np.concatenate((llrs_negative, llrs_positive))\n",
        "    all_targets = np.concatenate((np.zeros(llrs_negative.shape), np.ones(llrs_positive.shape)))\n",
        "    all_roc_scores.append(roc_auc_score(all_targets, all_llrs))\n",
        "\n",
        "print(\"Accuracy averaged across 20 random runs is\", np.array(all_roc_scores).mean())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy averaged across 20 random runs is 0.9039911308203992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDvfOYq3pz4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}